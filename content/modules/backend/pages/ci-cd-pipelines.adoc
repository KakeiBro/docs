= CI/CD Pipelines

Pipelines built with Github Actions, going all the way to the **Deployment** stage.

[NOTE]
====
By convention pipelines are setup in `.yml` files that are comitted to the repository. 
They should be all under `.github/workflows/`.
====

== Philosophy

The same philosophy we follow for the xref:frontend:ci-cd-pipelines#philosophy.adoc[Frontend's pipelines] 
is also followed on the _backend_.

Whilst we already have put a set of automation steps focused on each workstation through 
xref:git-hooks.adoc[Git Hooks], there are definitely many ways to circumvent those, 
and we shouldn't have to rely entirely on each developer's willingness to adhere 
to protocol but a centralized and (in theory) incorruptible source of thruth. 
Hence there are other mechanisms to keep tabs on code quality and correctness 
(according to a in-house set of rules).

- Pull Requests
- CI/CD Pipelines

For the backend we will focus on running all checking and building logic, with additional 
steps such as _Building a Docker Image_, _Uploading it to Google Cloud Artifact Registry_ 
and _Deploying that image in a Google Cloud Run instance_. Specifically for how things 
integrate with the Google Side of things, everything that's neccesary will be laid 
out at the <<Google Cloud Run>> and <<Docker image>> sections.

[NOTE]
====
And in that endeavor of making the pipelines to be as fast as possible, we will leverage 
caching, unlike the xref:frontend:ci-cd-pipelines.adoc#pr-pipeline[Frontend pipelines], 
we are going to cache both Docker layers, alongside NuGet packages with the usage of 
a `actions.cache` pre-built action script. This approach is a bit more manual, yet 
it leverages the same idea of packages that were already downloaded and we shouldn't 
have the need to download them again.
====

Due to the nature of the application, there are some security concerns tied with 
best practices that we should discuss in order to explain the decisions behind 
the pipelines design:

1. We should put behind variables and secrets references to versions or credentials, 
or things that in nature are dynamic and or sensitive.

Github has a feature to store sensitive data securely, you can configure 
https://github.com/github/docs/blob/main/content/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions.md[secrets] 
that way. That's simply a key-value structure attached to a repo, an environment or a 
whole organization. In our case we will use a **repository secrets store**.

=== Secrets

All values stored behind secrets contain sensitive information and should **not** be 
exposed in the workflow file. Github goes out of its way to completely obfuscate these 
values on logs and any other place that could leak their actual values.

[options="header"]
|===
| Variable           | Description
| `GCP_SA_KEY`      | Contains the JSON key for your Google Cloud service account, which grants access to deploy services. Must always be kept secret.
| `PROJECT_ID`      | While not as sensitive, it is generally a good practice to store it in secrets if you want to avoid accidental exposure.
| `ARTIFACT_REGISTRY` | If it's specific to your cloud provider and shouldn't be exposed in logs, store it in secrets.
| `REPOSITORY_NAME` | If you use private repositories in Artifact Registry, this should be secret.
| `IMAGE_NAME`      | If you use naming conventions that expose internal project details, store it in secrets.
|===

_NOTE:_ Once you add a secret to the vault, you will not be able to see its value ever 
again. So be mindful of that.

==== GCP

In order for the Github Action to be able to log into GCloud, push images and then deploy 
Cloud Run instances, we need to set a _Service Account Key_:

https://cloud.google.com/iam/docs/keys-create-delete#console[Reference]

The easiest way to get this is by using the GCloud Console web app and downloading the 
service key as a `.json` file. This should never be uploaded anywhere, but the github 
secrets vault. We should paste the whole json file as the value of the key.

_Note:_ Be sure to be under the correct google account and the correct project when generating 
this service key.

=== Variables

Following the same idea im programming to avoid magic numbers or strings, we should try 
to use variables, these in nature should be safe to explore in a workflow.

[options="header"]
|===
| Variable           | Description
| `DOTNET_VERSION`   | Just specifies which .NET version to use; no security concerns.
| `SERVICE_NAME`     | The Cloud Run service name is not sensitive.
| `REGION`          | The region is not sensitive unless you're trying to obscure deployment details.
| `CACHE_VERSION`    | Used for cache invalidation and not security-sensitive.
|===

== PR Pipeline

This consists of **one job**, "Build and Test".

=== Build and Test

Steps:

* Checkout code with pre-built script
* Setup `actions/setup-dotnet@v4` to use .NET 9
* Cache NuGet (and possible node) packages from .NET.
** `actions/cache@v4` is a built-in action using to cache files across workflow 
runs. (General approach not tech-stack specific).
** It specifices _what to cache_, .NET stores downloaded dependencies at `~/.nuget/packages`.
** We then build a unique key to identify if we have a current project state that has the 
same packages. The different components to this key are:
*** **runner.os** => The OS running the workflow (ubuntu-latest, windows-latest, etc)
*** **nuget** => A fixed identifier to describe the cache type.
*** **env.CACHE_VERSION** => A variable that can be incremented manually to force cache 
invalidation
*** A hash of `.csproj` and `packages.lock.json` files. If any of these files are changed, 
the cache **becomes invalid** and dependencies are downloaded again.
** We also have a fallback mechanism if the exact key isn't found that's built only 
with a partial prefix: `runner.os`-nuget-`env.CACHE_VERSION`.
*** E.g: If the key `ubuntu-latest-nuget-v1-abc123` isn't found, GitHub will try a less 
specific key like `ubuntu-latest-nuget-v1-`.
** **IMPORTANT:** This is probably one of the most important steps when it comes to 
speeding up builds, we avoid re-downloading dependencies, reduce network usage, and 
workflow consistency is enforced since we ensure we use the same dependencies across 
runs. For a bit more of a breakdown of how this step is idempotent and useful you can 
check out the <<GitHub Action Caching>> section.
* Restore dependencies
* Check code format 
* Build the project
* Run tests
* Check outdated packages
* Run vulnerabilities check

== Master Pipeline

This consists of **three jobs**, "Build and Test", "Build and push docker image" 
and "Deploy image to Cloud Run".

=== Build and Test

Steps:

* Checkout code with pre-built script
* Setup `actions/setup-dotnet@v4` to use .NET 9
* Cache NuGet (and possible node) packages from .NET.
** `actions/cache@v4` is a built-in action using to cache files across workflow 
runs. (General approach not tech-stack specific).
** It specifices _what to cache_, .NET stores downloaded dependencies at `~/.nuget/packages`.
** We then build a unique key to identify if we have a current project state that has the 
same packages. The different components to this key are:
*** **runner.os** => The OS running the workflow (ubuntu-latest, windows-latest, etc)
*** **nuget** => A fixed identifier to describe the cache type.
*** **env.CACHE_VERSION** => A variable that can be incremented manually to force cache 
invalidation
*** A hash of `.csproj` and `packages.lock.json` files. If any of these files are changed, 
the cache **becomes invalid** and dependencies are downloaded again.
** We also have a fallback mechanism if the exact key isn't found that's built only 
with a partial prefix: `runner.os`-nuget-`env.CACHE_VERSION`.
*** E.g: If the key `ubuntu-latest-nuget-v1-abc123` isn't found, GitHub will try a less 
specific key like `ubuntu-latest-nuget-v1-`.
** **IMPORTANT:** This is probably one of the most important steps when it comes to 
speeding up builds, we avoid re-downloading dependencies, reduce network usage, and 
workflow consistency is enforced since we ensure we use the same dependencies across 
runs. For a bit more of a breakdown of how this step is idempotent and useful you can 
check out the <<GitHub Action Caching>> section.
* Restore dependencies
* Check code format 
* Build the project
* Run tests
* Check outdated packages
* Run vulnerabilities check

=== Build and push docker image

Steps:

* Checkout code with built-in action
* Setup another specific built in action to build a docker image: 
`docker/setup-buildx-action@v3`
* Following the same pattern for caching as in <<Build and Test>>, we set a specific 
cache key built from `runner.os`-buildx-`env.CACHE_VERSION`-`github-sha`
** One difference is that the action we will use for building and then pushing will 
save its docker layers at `/tmp/.buildx-cache`, hence we reference that specific path.
** This optimization is micro in nature, since it will only re-use layers that are specific 
for a commit, hence `github.sha` is there to make the caches unique to a specific HEAD 
commit.
** And the fallback with omit that HASH, in any case, we will try our best to restore 
cached layers from previous runs and when running the docker build and all it will pick 
up on the things it can reuse or the things it can't. When the code changes (as new commits 
are pushed), the layers should be re-built in theory, hence we add the commit variable.
* We then make usage of another built-in repice: `docker/login-action@v3`. This takes 
parameters such as the **artifact registry** (that's the root, e.g: `your-region-docker.pkg-dev`), 
a **username** that if hard-set at __json_key_ it will expect to have the whole json 
string fed to it in the following filed under **password**.
* We leverage another built-in recipe: `docker/build-push-action@v4`. This in essence 
builds a Dockerfile and it then pushes that to a configured registry.
** The `context` is given through a parameter, since we have to be at the **solution folder** 
level we adjust it to **./Kakeibro.API**
** The action can be configured to not do a push by the end, but we want to so we 
set it to **true**.
** A **good practice** is to always push two tags, one referring to the new _latest_ 
and then another under the specific _commit_id_. But there's something to take into 
consideration here. **We are not pushing two images**. We are pushing one image, but 
that can be accessed by two different tags, a _latest_ one and a _commit-id_ one. 
In subsequent runs the _latest_ tag will point to the newer image that should also have 
its new _commit-id_ tag. Hence we are always pushing the _latest_ tag to the latest and 
just using references to make integration seamless. But this, overtime, can generate 
junk for stale images we won't use at all, for more info on this you can check out 
the <<Cleaning Image Registries>> section. 
** Under `cache-from` and `cache-to` we can configure the action to try to restore 
a previous cache (and notice how it's pointing to `/tmp/.buildx-cache`), and also save 
all layers and artifacts to the same location (so that our caching action can then 
save it for subsequent runs), and lastly with the `mode` parameter it will always try 
to store the maximum number of layers. This way Docker will only rebuild the layers 
that have changed, using the cached layers for everything else.

=== Deploy image to Cloud Run

Steps:

* Checkout code with built-in script
* We use another built-in action `google-github-actions/auth@v2`, that automatically 
receives a `credentials_json` and will authenticate with GCloud.
* We make sure we have the GCloud SDK setup so that we can start consuming the respective 
APIs to spin up an image from the Registry that has the latest pushed image from 
the <<Build and push docker image>> job. Luckily `google-github-actions/setup-gcloud@v2` 
takes care of abstracting all of that.
* We run a deploy to our configured `kakeibro-api` service with the same recommendations 
under <<Google Cloud Run>>, but now in a CLI command version. We will be always pushing 
the **latest** tag.

== Docker image

Since `.NET 8` a big emphasis was put into working with Docker out the box and with 
_best practices_ in mind. Hence, there's already a `Dockerfile` file already present in 
the repo from scaffolding directly, and it makes use of an `app` or `APP_UID` user 
to run the app and not `root`, and standard HTTP and HTTPS ports (8080, 8081 respectively).

The command to build the `API` project's Docker image is:

```
docker build -t kakeibro-api -f .\src\KakeiBro.API\Dockerfile .
```

By convention all scaffolded `Dockerfile` files are expecting to be **run at the solution 
folder level**, hence we have to be standing at `Kakibro.API` and from there run the command.

And in order to run a container manually you can do something like this:

```
docker run --rm -p 5214:8080 kakeibro-api
```

_Comment:_ When working with Visual Studio, you might also see a `Microsoft.VisualStudio.Azure.Containers.Tools.Targets` 
package installed, this is leveraged in order to generate `Dockerfile` files that are 
context aware, meaning that it will have all instructions referencing to the current state 
of the application, in case we use Visual Studio this could be useful, but for other 
IDE's this would be redundant.

[NOTE]
====
After the `app` user convention it was later published a new convention, hence we 
don't have to use `USER app` but `USER $APP_UID`. https://github.com/dotnet/dotnet-docker/issues/4506[Reference].
====

It's also worth noting that with xref:net-modulith#centralized-nuget-packages[Centralized Package Management]. 
`Dockerfile`s have to have some additions to the default structure:

```
# This stage is used to build the service project
FROM mcr.microsoft.com/dotnet/sdk:9.0 AS build
ARG BUILD_CONFIGURATION=Release
WORKDIR /src
COPY ["Directory.Packages.props", "."]
COPY ["Directory.Build.props", "."]
COPY ["src/KakeiBro.API/KakeiBro.API.csproj", "src/KakeiBro.API/"]
RUN dotnet restore "./src/KakeiBro.API/KakeiBro.API.csproj"
COPY . .
WORKDIR "/src/src/KakeiBro.API"
RUN dotnet build "./KakeiBro.API.csproj" -c $BUILD_CONFIGURATION -o /app/build
```
It is at the `restore` stage specifically, that if we don't have the `Directory.*` 
files copied at the same level, we won't be able to resolve the NuGet dependencies 
and other settings that should be tied to the specific project we are containerizing. 
Hence we have to **copy those files** and **then start the build process.**

== Google Cloud Run

**HINT:** https://www.youtube.com/watch?v=cw34KMPSt4k[Reference].

Leveraging the same xref:prototypes:o-auth.adoc[GCloud Console Project], we will 
make use of the _Artifact Registry_ and the _Cloud Run_ services in order to have 
docker images hosted plus spinning them up on demand (cold starts will be assumed).

After creating an _Artifact Registry_ repository, (in our case it is called _kakeibro-api_), 
we can then copy its URL (e.g: us-east1-docker.pkg.dev/kakeibro/kakeibro-api/<image-name>), 
and with that you can tag an existing image you have on your local machine `docker tag kakeibro-api <URL>`. 
And after that you can push the image by doing a `docker push <URL>`. All images that 
are under that repository will be pushed.

It is after an image is present in a registry that we can switch to _Cloud Run_ and then 
configure a service to spin up an instance of the service under that image.

[NOTE]
====
Don't forget to make the service to be unauthenticated (unless you want to leverage 
Google Auth as an intermediate layer), but either way, if you turn this off any public 
IP will be able to talk to the instance.
====

We are setting it up with `1 GB` ram, and for it to not have a minimum number of 
instances, and that is due to the fact we will incurr in billing costs if we do allocate 
it.

Once we have tied the service to our docker image and start the service, after GCloud 
has allocated the resources and everything behind the scenes, we should be able to hit 
the endpoint in the cloud and we should be getting back something. We can also configure 
custom domains, and in our case we will leverage the `dsbalderrama.top` domain that has 
been purchased, to map a web url to it, but specific to our _KakeiBro_ domain.

This involves going into the **domain provider's website**, and adding **CNAME** records that 
GCloud Console provides to us in a **step-by-step window**. It will take some time for 
**provisioning** though, so just wait until GCloud has **synchronized itself** with the DNS 
replication.

[IMPORTANT]
====
When trying to construct the URL to push the image, at the beginning you will have an 
empty repository folder, you need to then add a last segment for the name of the file that will 
be the image. E.g: <region-server>/kakeibro/<kakeibro-api>. The last _kakeibro-api_ 
is the name of the actual image file. If you don't add the last segment you will get an 
error.
====

Now pushing will not work unless you are logged into GCloud, you need the xref:ROOT:onboarding/index.adoc[gcloud CLI] 
installed for that. With it, you should log into your account that has the project that 
will host the **docker image** alongside the **cloud run instance**.

- `gcloud auth login`
- `gcloud config set project PROJECT_ID`

Once you have been logged in, and you are at the specific GCloud project (the ID can 
be retrieved from the list of project's at the home page of GCloud Console). You should 
be able to push the docker image normally.

Lastly, the **endpoint URL for the service** is **https://kakeibro-api.dsbalderrama.top**

== GitHub Action Caching

This is a quick breakdown of how the `actions/cache@v4` works:

[options="header"]
|===
| Condition                                 | Behavior
| Cache exists and matches the key          | Dependencies are restored from cache.
| Cache exists but doesn't fully match      | GitHub restores from the closest matching restore-keys prefix.
| Cache doesn't exist                        | Dependencies are downloaded, then saved to cache for future runs.
|===

In short, we try to get from an _external nebulous site_ our cached dependencies and they 
get restored (copied) into the current action run (at least they try their best to).

== Cleaning Image Registries

A **good practice** is to periodically clean up stale image tags, especially in a 
CI/CD pipeline that generates a lot of tags over time (like commit-specific ones). 
Unmanaged or redundant image tags can lead to unnecesary storage costs and clutter 
in your registry.

. Retention Policy
+
The `latest` tag should always be updated, and we should only have **one**. Commit hash 
tags are useful for referencing specific versions, but since they can accumulate over time, 
we can remove old commit tags, and lastly, we can add versioning to our tags, however, 
we hould also remove them when no longer used.
. Automating Cleanup
+

. Best Practices for Cleanup
. GCP Artifact Registry Cleanup

=== CRON GitHub Action